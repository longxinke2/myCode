{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from lxml import etree\n",
    "import re\n",
    "import pandas as pd\n",
    "from fake_useragent import UserAgent\n",
    "import requests_proxy\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 爬公司"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "park_name = []\n",
    "company_name = []\n",
    "legal_representative = []\n",
    "set_money = []\n",
    "create_time = []\n",
    "code = []\n",
    "tel = []\n",
    "email = []\n",
    "address = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    " parkid_group= ['26c5e11f5e8a4dbfbc3b63b2606d5368', '77603bb24fc91c0b7d43b9bed982a7d0', '25ed5da0d2e13f482037730137ffc07e', 'e233e9336656f0ab7ca1980515822b95', '5ccf04c140ea6c03076e53a477866319', '4fed92e99bcfebb99463916d91cf03cf', '4855acf4943e0d6ec0f42ae35218a381', 'fa66662f0c5781f8ade2a45646c34323', '238af801b04f706fdd342a5958a4b9b3', 'b2da5420b7e5ad7119bf0d00ed445859', 'e9d6be83e2122462eb792c280ab0510b', 'f3897f99171be50fc9240be9d03eaf78', '2d06ca35e0530069d8da7b7c8227666f', 'be48e1ed67ca568431b050b85145ce6f', 'f5503b4171813578cc3ca4547f659bd1', '39ae234371ef48c49639c9b22701c0cf', '201a6d79a259abe0eb833291f29cefa6', 'de1faf4bd2e89f621757c01975663248', '7a158927158ea5c1e8682a0c41722715', '16a611474ac04a2c49415af8c4ab0dba', '23cd789f4e5cb08047d96a0eb927d4a1', 'e41afbe96788fcee0cc6c21229a892fc', '7b041c72978d78c079610513c66565f5', '285f881879004833a76d325495ed6384', '9abe01b671358c8822a76211d39c6d6e', '5fa64b59a43faa20136d04c578a7071f', '92cf86c4554964b59dc0f801cb31ccc8', 'd9d76f153e2fcfd43a18b4426cd49dd6', 'fe6b582f04c2218bb7638731b13af0a5', '062451cf9e263518f1f0ea3d03e03137', '3bc4db1a17cdff76ab14059a168e0141', 'f801debbbb9318c8453c2e58ae28c29d', '3e274d8a0a13bb91842854f464eea2ad', '39164a720609d988f1e73e36d8b64e29', 'fd60dc78c1654926d0f5d8abdb65ae95', '8acfb404a26ce80e7053115375305f1c', '094f1b1a27c919ca0202a89120e62065', '0ccc545275c4ff8479ec5c57bccc57f0', '58d92af66430bf05cd60e92b79ce061f', 'a07d07c96f0b62881a9fe27579ea9da0', '0b391267a4a002859ea847c8b9e2cda0', 'ae5a9886388a35261865f2d79c7116f5', '294cd8740b89f99ddfbd6dfcfbe1dbb9', '2dce38c44a6d41f74eb236d59daeec3c', 'c92e46a1d29bcfe74935ec139bfd9338', '30dce396c84340021429c3443297f5f6', '1d7429a4590864322282eb5efd04c3fb', 'c35fb7c8b2ce59255d9aef9978a5348e', 'a59ad95bfc5e232ade3f022665e0ccb0', '2c01618caa770feb953d21cb3a60a18b', 'a44147948a25b0c598e163349223c8f6', '5e90b0cf921bec7288be34a3cdddb302', 'e89905cc01f74c9e93853527362b1ef3', '20bf3f0283aece5350f1138d47642b45', 'e1ff389c69247ab00a51e1e5cb649d7f', 'e04fce4a11668c59e097eeeaf8af18c5', '83c3d4b0503f394ad2c020bb592465b9', '584bee8231bcf835c90ebc7f112b288d', '2364c062b539559204710e3bd240e24b', 'e40ec5ef7b83136cd2de039c2158093c', 'd5ade00ff47475e296fa7e89d9f24d8e', '644122ddea178eea2d060036f1a5761b', '70fff90f61965879e86f669bbc15617f', 'd250e6ea9805d6c16b677c5473b97478', '2febb67a189971293008657ef9225481', '91739ae154f055835a5cdf2159b06748', '2325e9a1c0db080dec6c0274b94baa11', 'd3d25b1279ea4d15e8228d1eb79f6419', '083b4cf043e4401917d13fc8f006dc7d', '8010f9e0d5170f4088f4dd3f1545f723', 'cc0cd7e769aad989e243a55e30992d33', 'c88c0920a63174b6c8c7350a7471498f', '4374da35c0364608a1beb9740e837486', '9072c6fbf93e29ea41f4e60c1af8aa88', 'a37ed6179407a0533930521e678d3afb', '124edc60b82a9257ef69747d499c2f61', 'f7d5402dbb15c20e4297132c29b72864', 'c887df15b108a2c2ec7bbc1eee9b364d', 'ac9e845ffc4e273a74eeb336d59851a7', '17d4c4aeb04502ec99f0adeaf8ff882e', '22c6d1dc03e168e015b088b7d83c28d3', 'cbd16c14ec75a41922047a6229783d3c', '8ad90112d73dc22fdb7c4dacae07b49e', '94235ceea8d2d3f9b9bf6de44af5017a', '2b97464bf5fc88e48d2a08d0034fa679', '9bdc2b7439cce54c078ba418f2c89b5d', '34b2ae63fc1e1becf2ce1ca53cd84535', '6d823d72838c23355c3bd3ae6ef25b9c', '7082720ae242eeafb78b1e8169815adc', 'd522bad882a69ee0197449b6fb93c025', 'f6c22f3388cc53fae75eb6993b374e5a', 'ccfba1c41b5e6d1cbd56d6d36485099c', '441992d009822eb139252bce305af1fd', '83295397f7dd3a6b1b10e8dc98188f7a', '375b5c659e6c4b76cf19c28819088c3a']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def get_url(parkid):\n",
    "    global park_name,company_name,legal_representative,set_money,create_time,code,tel,email,address\n",
    "    url = f'https://www.qcc.com/zonecompany/{parkid}.html'\n",
    "    headers = {\n",
    "        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.3'}\n",
    "    response = requests.get(url, headers=headers)\n",
    "    text = str(response.text)\n",
    "    soup = BeautifulSoup(response.text,'html.parser')\n",
    "    company_num = int(re.findall('\\d+',soup.find_all('span',class_='text-danger')[0].string)[0])\n",
    "    page = company_num//10+1\n",
    "    parkname = soup.title.string.replace(' - 企查查','')\n",
    "    \n",
    "    for i in range(1,page+1):\n",
    "        url = f'https://www.qcc.com/zonecompany/{parkid}.html?p={i}'\n",
    "        response = requests.get(url, headers=headers)\n",
    "        text = str(response.text)\n",
    "        soup = BeautifulSoup(response.text,'html.parser')\n",
    "        company_namet = [i.string if isinstance(i, type(None)) ==False else '-' for i in soup.find_all('a',class_='title copy-value')]\n",
    "        if i != page and len(company_namet)!=10:\n",
    "            print(f'第{i}页报错')\n",
    "            raise\n",
    "        company_name += company_namet\n",
    "        \n",
    "        legal_representativet = [i.find('a').string if isinstance(i.find('a'), type(None)) ==False else '-' for i in soup.find_all('div',class_='rline rline-disInline')]\n",
    "        if i != page and len(legal_representativet)!=10:\n",
    "            print(f'第{i}页报错')\n",
    "            raise\n",
    "        legal_representative += legal_representativet \n",
    "        \n",
    "        set_moneyt = [i.find('span',class_='val').string if isinstance(i.find('span',class_='val'), type(None)) ==False else '-' for i in soup.find_all('div',class_='rline rline-disInline')]\n",
    "        if i != page and len(set_moneyt)!=10:\n",
    "            print(f'第{i}页报错')\n",
    "            raise\n",
    "        set_money += set_moneyt\n",
    "        \n",
    "        create_timet = [i.find_all('span',class_='val')[1].string if isinstance(i.find_all('span',class_='val')[1], type(None)) ==False else '-' for i in soup.find_all('div',class_='rline rline-disInline')]\n",
    "        if i != page and len(create_timet)!=10:\n",
    "            print(f'第{i}页报错')\n",
    "            raise\n",
    "        create_time += create_timet\n",
    "        \n",
    "        codet = [i.find('span',class_='copy-value').string if isinstance(i.find('span',class_='copy-value'), type(None)) ==False else '-' for i in soup.find_all('div',class_='rline rline-disInline')]\n",
    "        if i != page and len(codet)!=10:\n",
    "            print(f'第{i}页报错')\n",
    "            raise\n",
    "        code += codet\n",
    "        \n",
    "        telt = re.findall(r'电话：<.*?>(.*?)</span>', text)\n",
    "        if i != page and len(telt)!=10:\n",
    "            print(f'第{i}页报错')\n",
    "            raise\n",
    "        tel += telt\n",
    "        \n",
    "        emailt = re.findall(r'邮箱：<.*?>(.*?)</span>', text)\n",
    "        if i != page and len(emailt)!=10:\n",
    "            print(f'第{i}页报错')\n",
    "            raise\n",
    "        email += emailt\n",
    "        \n",
    "        addresst = re.findall(r'地址：<.*?>(.*?)</span>', text)\n",
    "        if i != page and len(addresst)!=10:\n",
    "            print(f'第{i}页报错')\n",
    "            raise\n",
    "        address += addresst\n",
    "        \n",
    "    park_name = park_name + [parkname] * company_num\n",
    "    group_list = [company_name,legal_representative,set_money,create_time,code,tel,email,address]\n",
    "    for group_index in range(0,len(group_list)):\n",
    "        if len(park_name) != len(group_list[group_index]):\n",
    "            print(f'第{group_index}个字段长度不一致')\n",
    "            raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for i in range(51,len(parkid_group)):# 下次从51开始\n",
    "    try:\n",
    "        get_url(parkid_group[i])\n",
    "    except:\n",
    "        print(parkid_group[i]+'报错')\n",
    "        raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5492"
      ]
     },
     "execution_count": 253,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(park_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5489"
      ]
     },
     "execution_count": 254,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(company_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.to_excel('公司2.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 爬公司\n",
    "df1 = pd.DataFrame({\n",
    "    'park_name': park_name,\n",
    "    'company_name': company_name,\n",
    "    'legal_representative': legal_representative,\n",
    "    'registered_money': set_money,\n",
    "    'create_time': create_time,\n",
    "    'code': code,\n",
    "    'tel': tel,\n",
    "    'email': email,\n",
    "    'address': address\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 爬产业园"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "park_name = []\n",
    "province = []\n",
    "city = []\n",
    "area = []\n",
    "company_num = []\n",
    "for i in range(1,2):\n",
    "    num = i\n",
    "    global park_name,province,city,area,company_num\n",
    "    url = f'https://www.qcc.com/web/more/zone?searchKey=&province=GS&provincedesc=%E7%94%98%E8%82%83&areacode=&p={num}&sortField=companynum-false'\n",
    "    headers = {\n",
    "        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.3'}\n",
    "\n",
    "    # 发送请求\n",
    "    response = requests.get(url, headers=headers)\n",
    "    text = str(response.text)\n",
    "    soup = BeautifulSoup(response.text,'html.parser')\n",
    "    for item in soup.find_all('a',class_='zone-item'):\n",
    "        park_name.append(item.find('div',class_='zone-item-title').string)\n",
    "        province.append(item.find_all('span',class_='val')[0].string)\n",
    "        city.append(item.find_all('span',class_='val')[1].string)\n",
    "        area.append(item.find_all('span',class_='val')[2].string)\n",
    "        company_num.append(item.find_all('span',class_='val')[3].string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2=pd.DataFrame({\n",
    "    'park_name':park_name,\n",
    "    'province':province,\n",
    "    'city':city,\n",
    "    'area':area,\n",
    "    'company_num':company_num\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 其他"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.to_excel('E:/桌面/爬虫结果/公司1.xlsx')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 草稿"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = f'https://www.polyt.cn/#/search'\n",
    "headers = {\n",
    "    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.3'}\n",
    "response = requests.get(url, headers=headers)\n",
    "soup = BeautifulSoup(response.text,'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "mytemp = soup.find('div',class_='entry-content u-text-format u-clearfix')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "line = 0\n",
    "h3 = []\n",
    "gw = []\n",
    "dh = []\n",
    "dz = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0,len(text)):\n",
    "    if text[i].name == 'h3':\n",
    "        h3.append(text[i].text)\n",
    "        gw.append(text[i+1].text)\n",
    "        dh.append(text[i+2].text)\n",
    "        dz.append(text[i+3].text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = mytemp.find_all(['h3','li'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "41"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(mytemp.find_all(['h3', 'h4']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2=pd.DataFrame({\n",
    "    'park_name':h3,\n",
    "    'province':gw,\n",
    "    'city':dh,\n",
    "    'area':dz\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.to_excel('E:/桌面/12.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "221----                                              8%"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import lxk\n",
    "data_school = pd.DataFrame([],columns=['学校名称','地区','属性','性质','类型','评分人数','学校地址','电话'])\n",
    "error_group = []\n",
    "import requests\n",
    "import re\n",
    "from bs4 import BeautifulSoup\n",
    "j=1\n",
    "max_page = 1\n",
    "while j<=max_page:\n",
    "    url = f'http://xuexiao.51sxue.com/slist/?o=&t=1&areaCodeS=&level=&sp=&score=&order=&areaS=%C8%AB%B9%FA&searchKey=&page={j}'\n",
    "    headers = {\n",
    "        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.3'}\n",
    "\n",
    "    response = requests.get(url, headers=headers)\n",
    "    try:\n",
    "        text = response.content.decode('gb2312')\n",
    "    except:\n",
    "        error_group.append(j)\n",
    "        j+=1\n",
    "        continue\n",
    "    soup = BeautifulSoup(text,'html.parser')\n",
    "    group = soup.find_all('div',class_='reply_box')\n",
    "    for k in range(len(group)):\n",
    "        data_school.loc[len(data_school)]=[group[k].find('h3').text]+[x.text for x in group[k].find_all('b')]\n",
    "    if max_page==1:\n",
    "        max_page=int(re.sub('共','',soup.find('span',class_='down').text))\n",
    "    lxk.progress_bar(str(j),j,max_page)\n",
    "    j+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'text/html;charset:gb2312'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.headers.get('Content-Type', '').split('charset=')[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
